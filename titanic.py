# -*- coding: utf-8 -*-
"""titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17W9oh6WezVbzn00PDZiaqyJwCmf3CTws
"""

import pandas as pd
import numpy as np

train=pd.read_csv("train.csv")
test=pd.read_csv("test.csv")

print(train.columns.values)

print (train.isnull().sum())

print(train.shape)

print(train.dtypes)
print(train.head())
print('*'*50)
print (train.tail())

print(train.describe(include=['O'] ))

train[['Pclass','Survived']].groupby(['Pclass'],as_index=False).mean().sort_values(by='Survived',ascending=False)

train[['Sex','Survived']].groupby(['Sex'],as_index=False).mean().sort_values(by='Survived',ascending=False)

train[['SibSp','Survived']].groupby(["SibSp"],as_index=False).mean().sort_values(by='Survived',ascending=False)

train[["Parch",'Survived']].groupby(by='Parch').mean().sort_values(by='Survived',ascending=False)

import seaborn as sns
import matplotlib.pyplot as plt
g=sns.FacetGrid(train,col='Pclass',row='Survived')
g.map(plt.hist,'Age',bins=20)

g1=sns.FacetGrid(train,col='Pclass',row='Survived')
g1.map(plt.hist,'Sex')

grid=sns.FacetGrid(train,row='Embarked')
grid.map(sns.pointplot,'Pclass','Survived','Sex')
grid.add_legend()

grid1=sns.FacetGrid(train,row='Embarked',col='Survived')
grid1.map(sns.barplot,'Sex','Fare')

print(train['Cabin'].isnull().sum())

train=train.drop(['Ticket','Cabin'],axis=1)
test=test.drop(['Ticket','Cabin'],axis=1)
combine=[train,test]
print(combine[0].shape)
print(combine[1].shape)

for data in combine:
  data['Title']=data.Name.str.extract('([A-Za-z]+)\.',expand=False)
pd.crosstab(train['Title'],train['Sex'])

for data in combine:
  data['Title']=data['Title'].replace(['Lady', 'Countess','Capt', 'Col',\
 	'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')
  data['Title']=data['Title'].replace('Mlle','Miss')
  data['Title'] = data['Title'].replace('Ms', 'Miss')
  data['Title'] = data['Title'].replace('Mme', 'Mrs')
train[['Title','Survived']].groupby(by='Title').mean()

titlemap={"Mr": 1, "Miss": 2, "Mrs": 3, "Master": 4, "Rare": 5}
for data in combine:
  data['Title']=data['Title'].map(titlemap)
  data['Title']=data['Title'].fillna(0)

train.columns
train=train.drop(['Name','PassengerId'],axis=1)
test=test.drop(['Name'],axis=1)
print(train.shape)
print(test.shape)
combine=[train,test]

for dataset in combine:
    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} )

train.head()

for data in combine:
  print(data.isnull().sum())
  print('-'*30)

grid=sns.FacetGrid(train,col='Sex',row='Pclass',height=2.2,aspect=1.6)
grid.map(plt.hist,'Age')
grid.add_legend()

test.describe()

train['Age'].fillna(30,inplace=True)
test['Age'].fillna(30,inplace=True)
combine=[train,test]
for data in combine:
  print(data.isnull().sum())
  print('-'*30)
print(train['Age'])

train['AgeBand']=pd.cut(train['Age'],5)
train['AgeBand']
train[['AgeBand','Survived']].groupby('AgeBand',as_index=False).mean().sort_values(by='AgeBand',ascending=False)

for data in combine:
  data.loc[ data['Age'] <= 16, 'Age'] = 0
  data.loc[(data['Age'] > 16) & (data['Age'] <= 32), 'Age'] = 1
  data.loc[(data['Age'] > 32) & (data['Age'] <= 48), 'Age'] = 2
  data.loc[(data['Age'] > 48) & (data['Age'] <= 64), 'Age'] = 3
  data.loc[ data['Age'] > 64, 'Age']
train.head()

train=train.drop(['AgeBand'],axis=1)
combine=[train,test]
train.head()

train.describe(include='O')

train['Embarked']=train['Embarked'].fillna('S')
print(train['Embarked'].isnull().sum())
train[['Embarked','Survived']].groupby('Embarked',as_index=False).mean().sort_values(by='Survived',ascending=False)

combine=[train,test]
for data in combine:
  data['Embarked']=data['Embarked'].map({'S':0,'C':1,'Q':2}).astype(int)
train.head()

test['Fare'].fillna(35,inplace=True)
test.isnull().sum()
train.isnull().sum()

train['FareBand']=pd.qcut(train['Fare'],4)
train[['FareBand','Survived']].groupby('FareBand',as_index=False).mean().sort_values(by='FareBand',ascending=False)

for data in combine:
  data.loc[data['Fare']<=7.91,'Fare']=0
  data.loc[(data['Fare']>=7.91)&(data['Fare']<=14.454),'Fare']=1
  data.loc[(data['Fare']>=14.454)&(data['Fare']<=31.0),'Fare']=2
  data.loc[(data['Fare']>=31.0)&(data['Fare']<=512.39),'Fare']=3
  data['Fare']=data['Fare'].astype(int)
combine=[train,test]
print(train.columns.values)
print(train.shape)
print(train.head())

combine=[train,test]
for data in combine:
  data['Family']=data['Parch']+data['SibSp']+1
train[['Family','Survived']].groupby(['Family'],as_index=False).mean().sort_values(by='Survived',ascending=False)
for data in combine:
  data['isalone']=0
  data.loc[data['Family']==1,'isalone']=1
train[['isalone','Survived']].groupby('isalone',as_index=False).mean().sort_values(by='Survived')

train=train.drop(['SibSp','Parch','Family','FareBand'],axis=1)
test=test.drop(['SibSp','Parch','Family'],axis=1)
print(train.columns.values)
print(test.columns.values)

train['Age']=train['Age'].astype('int')
train.dtypes

from sklearn.model_selection import train_test_split as tts
X=train.drop(['Survived'],axis=1)
y=train['Survived']
X_train,X_test,y_train,y_test=tts(X,y,test_size=0.2,random_state=2)
print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)

"""Fitting the data with models
1.  Logistic regression
2.  K-nearest neighbours
3.  SVM
4.  Decision Trees
5.  RandomForests
6.  perceptron
"""

from sklearn.linear_model import LogisticRegression 
from sklearn.neighbors import KNeighborsClassifier 
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier 
from sklearn.ensemble import RandomForestClassifier 
from sklearn.neural_network import MLPClassifier 
from sklearn.model_selection import RandomizedSearchCV

log=LogisticRegression()
log.fit(X_train,y_train)
print('trainingscore:',round(log.score(X_train,y_train)*100,2))
print('testscore:',round(log.score(X_test,y_test)*100,2))

knn=KNeighborsClassifier()
knn.fit(X_train,y_train)
print('trainingscore:',round(knn.score(X_train,y_train)*100,2))
print('testscore:',round(knn.score(X_test,y_test)*100,2))

svm=SVC()
svm.fit(X_train,y_train)
print('trainingscore:',round(svm.score(X_train,y_train)*100,2))
print('testscore:',round(svm.score(X_test,y_test)*100,2))

tree=DecisionTreeClassifier()
tree.fit(X_train,y_train)
print('trainingscore:',round(tree.score(X_train,y_train)*100,2))
print('testscore:',round(tree.score(X_test,y_test)*100,2))

forest=RandomForestClassifier()
forest.fit(X_train,y_train)
print('trainingscore:',round(forest.score(X_train,y_train)*100,2))
print('testscore:',round(forest.score(X_test,y_test)*100,2))

nn=MLPClassifier()
nn.fit(X_train,y_train)
print('trainingscore:',round(nn.score(X_train,y_train)*100,2))
print('testscore:',round(nn.score(X_test,y_test)*100,2))

